---
title: "Data 621 Homework 5"
author: "Mark Gonsalves, Joshua Hummell, Claire Meyer, Chinedu Onyeka, Rathish Parayil Sasidharan"
date: "5/2/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning = FALSE)
```


```{r warning = FALSE, message = FALSE}
library(Amelia)
#library(rpart.plot)
#library(ggfortify)
#library(gridExtra)
#library(forecast)
#library(fpp2)
#library(fma)
library(kableExtra)
#library(e1071)
#library(mlbench)
library(ggcorrplot)
#library(DataExplorer)
library(timeDate)
library(caret)
#library(GGally)
library(corrplot)
library(RColorBrewer)
library(tidyverse)
library(caTools)
library(visdat)
#library(reshape2)
#library(mixtools)
#library(tidymodels)
#(ggpmisc)
#library(regclass)
#library(skimr)
#library(RANN)
#library(Hmisc)
```

## Overview

In this homework assignment, you will explore, analyze and model a data set containing information on 
approximately 12,000 commercially available wines. The variables are mostly related to the chemical properties of 
the wine being sold. The response variable is the number of sample cases of wine that were purchased by wine 
distribution companies after sampling a wine. These cases would be used to provide tasting samples to 
restaurants and wine stores around the United States. The more sample cases purchased, the more likely is a 
wine to be sold at a high end restaurant. A large wine manufacturer is studying the data in order to predict the 
number of wine cases ordered based upon the wine characteristics. If the wine manufacturer can predict the 
number of cases, then that manufacturer will be able to adjust their wine offering to maximize sales

Your objective is to build a count regression model to predict the number of cases of wine that will be sold 
given certain properties of the wine. HINT: Sometimes, the fact that a variable is missing is actually predictive of 
the target. You can only use the variables given to you (or variables that you derive from the variables provided).
Below is a short description of the variables of interest in the data set


```{r echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
vr <- c("INDEX", "TARGET", "AcidIndex", "Alcohol", "Chlorides", "CitricAcid", "Density", "FixedAcidity", "FreeSulfurDioxide", "LabelAppeal", "ResidualSugar", "STARS", "Sulphates", "TotalSulfurDioxide", "VolatileAcidity", "pH")

def <- c("Identification Variable (do not use)", "Number of Cases Purchased", "Proprietary method of testing total acidity of wine by using a weighted average", "Alcohol Content", "Chloride content of wine", "Citric Acid Content", "Density of Wine", "Fixed Acidity of Wine", "Sulfur Dioxide content of wine", "Marketing Score indicating the appeal of label design for consumers. High numbers suggest customers like the label design. Negative numbers suggest customes don't like the design.", "Residual Sugar of wine", "Wine rating by a team of experts. 4 Stars = Excellent, 1 Star = Poor", "Sulfate conten of wine", "Total Sulfur Dioxide of Wine", "Volatile Acid content of wine", "pH of wine")

te <- c("None", "None", "", "",  "", "", "", "",  "", "Many consumers purchase based on the visual appeal of the wine label design. Higher numbers suggest better sales", "", "A high number of stars suggests high sales",  "", "", "", "")

kable(cbind(vr, def, te), col.names = c("Variable Name", "Definition", "Theoretical Effect")) %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>% scroll_box(width="100%",height="300px")
```





## 1. Data Exploration

### Dataset



```{r load_data, message=FALSE, warning=FALSE}

url_train <- "https://raw.githubusercontent.com/chinedu2301/data621-business-analytics-data-mining/main/assignments/assignment5/wine-training-data.csv"
url_eval  <- "https://raw.githubusercontent.com/chinedu2301/data621-business-analytics-data-mining/main/assignments/assignment5/wine-evaluation-data.csv"
training_df <- read.csv(url_train) %>% as.tibble()
eval_df <- read.csv(url_eval) %>% as.tibble()

```


**Get the dimension of the training dataset**  
```{r training-dimension}
dim(training_df)
```

The wine data set contains 16 variables including the target variable 'TARGET' variable and 12795 observations. 



**Get a glimpse of the training dataset** 
```{r training-glimpse}
glimpse(training_df)
```

We could see that data set contains only numerical variables, some of them are  discrete with limited number of values.
Since the Index column had no impact on the target variable,  it can be dropped from training and evaluation data. 
```{r headers-training}
headers <- c("INDEX", "TARGET", "FixedAcidity", "VolatileAcidity", "CitricAcid", "ResidualSugar", "Chlorides", "FreeSulfurDioxide", "TotalSulfurDioxide", "Density", "pH", "Sulphates", "Alcohol", "LabelAppeal", "AcidIndex", "STARS")
colnames(training_df) <- headers
head(training_df)
```
```{r headers-eval}
head(eval_df)
```



```{r drop-index}

df_train <- training_df %>% select(-INDEX)

df_eval <- eval_df %>% select(-IN)
```


### Summary Stats


```{r echo=FALSE}
summary(df_train)
```




### Distributions


Let's look at the distribution of each variables in the dataset.

```{r, fig.height = 10, fig.width = 10, echo=FALSE}

gather_df <- df_train %>% 
  gather(key = 'variable', value = 'value')

# Histogram plots of each variable
ggplot(gather_df) + 
  geom_histogram(aes(x=value, y = ..density..), bins=30) + 
  facet_wrap(. ~variable, scales='free', ncol=4) 
```

We could see that most variables have a somewhat normally distributed.

The distribution profiles show right skew in variables 'AcidIndex', and 'STARS'. 
Also we could notice that some of these variables like STARS, Target ,LabelAppeal etc have discrete values , meaning they are categorical.




### Boxplots

We could analyze the spread of each variables using a box-plot.

```{r, fig.height = 10, fig.width = 10, echo=FALSE}

# Boxplots for each variable
ggplot(gather_df, aes(variable, value)) + 
  geom_boxplot() + 
  facet_wrap(. ~variable, scales='free', ncol=6)
```

There is not much outliers in the variables.



### Missing Data

We have already noticed that there are many missing values in the dataset. Let's analyze the distribution of missing values

```{r echo=FALSE}
is_missing <- function(x){
  missing_strs <- c('', 'null', 'na', 'nan', 'inf', '-inf', '-9', 'unknown', 'missing')
  ifelse((is.na(x) | is.nan(x) | is.infinite(x)), TRUE,
         ifelse(trimws(tolower(x)) %in% missing_strs, TRUE, FALSE))
}

missing_summary<-summarise_all(df_train, ~(sum(is_missing(.) / nrow(df_train))))

stack(sort(missing_summary, decreasing = TRUE))

```
```{r missingness-map}
missmap(df_train, col = c("yellow", "black"), main = "Missingness Map - Training Dataset")
```


We could see STARS has lot of missing values ,almost 26%.

We are going to replace the NA value for STARS  with zero.

```{r echo=TRUE}
df_train["STARS"][is.na(df_train["STARS"])] <- 0
df_eval["STARS"][is.na(df_eval["STARS"])] <- 0
```


### Correlations with Target



```{r echo=FALSE}
clean_df <- df_train
stack(sort(cor(clean_df[,1], clean_df[,2:ncol(clean_df)])[,], decreasing=TRUE))
```

We could see that 'STARS`, 'LabelAppeal', and 'AcidIndex' have the highest correlation with 'TARGET'.

### Multicolinearity


```{r echo=FALSE, fig.height=8}

correlation = cor(clean_df, use = 'pairwise.complete.obs')
corrplot(correlation, 'ellipse', type = 'lower', order = 'hclust',
         col=brewer.pal(n=8, name="RdYlBu"))
```

We see that the features have very low correlations with each other, meaning that there is not much multicolinearity present in the dataset. 
This means that the assumptions of linear regression are more likely to be met.

## 2. Data Preparation

**Fix missing values**
```{r}
is_missing <- function(x){
  missing_strs <- c('', 'null', 'na', 'nan', 'inf', '-inf', '-9', 'unknown', 'missing')
  ifelse((is.na(x) | is.nan(x) | is.infinite(x)), TRUE,
         ifelse(trimws(tolower(x)) %in% missing_strs, TRUE, FALSE))
}
```


Replace na values with mean
```{r replace-missing-training}
clean_df$STARS[is_missing(clean_df$STARS)] <- median(clean_df$STARS, na.rm = TRUE)
clean_df$Sulphates[is_missing(clean_df$Sulphates)] <- mean(clean_df$Sulphates, na.rm = TRUE)
clean_df$TotalSulfurDioxide[is_missing(clean_df$TotalSulfurDioxide)] <- mean(clean_df$TotalSulfurDioxide, na.rm = TRUE)
clean_df$FreeSulfurDioxide[is_missing(clean_df$FreeSulfurDioxide)] <- mean(clean_df$FreeSulfurDioxide, na.rm = TRUE)
clean_df$Alcohol[is_missing(clean_df$Alcohol)] <- mean(clean_df$Alcohol, na.rm = TRUE)
clean_df$Chlorides[is_missing(clean_df$Chlorides)] <- mean(clean_df$Chlorides, na.rm = TRUE)
clean_df$ResidualSugar[is_missing(clean_df$ResidualSugar)] <- mean(clean_df$ResidualSugar, na.rm = TRUE)
clean_df$pH[is_missing(clean_df$pH)] <- mean(clean_df$pH, na.rm = TRUE)
clean_df$FixedAcidity[is_missing(clean_df$FixedAcidity)] <- mean(clean_df$FixedAcidity, na.rm = TRUE)
# assign the clean dataframe to training
training = clean_df
```

Map of Missing Data

```{r missingness-map-visdat}
vis_dat(training)
```
```{r missingness-map-training-amelia}
missmap(training, col = c("yellow", "black"), main = "Missingness Map - Training Dataset")
```



Replace missing values for evaluation dataset
```{r replace-missing-eval}
df_eval$STARS[is_missing(df_eval$STARS)] <- median(df_eval$STARS, na.rm = TRUE)
df_eval$Sulphates[is_missing(df_eval$Sulphates)] <- mean(df_eval$Sulphates, na.rm = TRUE)
df_eval$TotalSulfurDioxide[is_missing(df_eval$TotalSulfurDioxide)] <- mean(df_eval$TotalSulfurDioxide, na.rm = TRUE)
df_eval$FreeSulfurDioxide[is_missing(df_eval$FreeSulfurDioxide)] <- mean(df_eval$FreeSulfurDioxide, na.rm = TRUE)
df_eval$Alcohol[is_missing(df_eval$Alcohol)] <- mean(df_eval$Alcohol, na.rm = TRUE)
df_eval$Chlorides[is_missing(df_eval$Chlorides)] <- mean(df_eval$Chlorides, na.rm = TRUE)
df_eval$ResidualSugar[is_missing(df_eval$ResidualSugar)] <- mean(df_eval$ResidualSugar, na.rm = TRUE)
df_eval$pH[is_missing(df_eval$pH)] <- mean(df_eval$pH, na.rm = TRUE)
df_eval$FixedAcidity[is_missing(df_eval$FixedAcidity)] <- mean(df_eval$FixedAcidity, na.rm = TRUE)
df_eval$VolatileAcidity[is_missing(df_eval$VolatileAcidity)] <- mean(df_eval$VolatileAcidity, na.rm = TRUE)
df_eval$CitricAcid[is_missing(df_eval$CitricAcid)] <- mean(df_eval$CitricAcid, na.rm = TRUE)
df_eval$Density[is_missing(df_eval$Density)] <- mean(df_eval$Density, na.rm = TRUE)
df_eval$LabelAppeal[is_missing(df_eval$LabelAppeal)] <- mean(df_eval$LabelAppeal, na.rm = TRUE)
df_eval$AcidIndex[is_missing(df_eval$AcidIndex)] <- mean(df_eval$AcidIndex, na.rm = TRUE)
evaluation = df_eval
```

```{r echo=FALSE}
#Amelia::missmap(df_eval, col = c("yellow", "black"), main = "Missingness Map - Training Dataset")
```

**Split the dataset**  
```{r split-dataset}
set.seed(101)

# Split the sample
sample <- sample.split(training$TARGET, SplitRatio = 0.8)

# Training sample data
wine_train <- subset(training, sample == TRUE)

# Test sample data
wine_test <- subset(training, sample == FALSE)

```

## 3. Build Models 








